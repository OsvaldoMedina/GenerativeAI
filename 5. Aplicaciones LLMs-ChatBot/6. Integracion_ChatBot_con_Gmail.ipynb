{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cb7b12c"
      },
      "source": [
        "# Caso Práctico: Integración del ChatBot con servicios externos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42e9ea52"
      },
      "source": [
        "<div style=\"background-color:#D9EEFF;color:black;padding:2%;\">\n",
        "<h2>Enunciado del caso práctico</h2>\n",
        "\n",
        "En este caso práctico, se propone al alumno la integración del ChatBot implementando en el caso práctico anterior con el servicio de correo electrónico de Gmail.\n",
        "\n",
        "La aplicación debe ser capaz de realizar diferentes funciones sobre los correos electrónicos del usuario. Por ejemplo, debe ser capaz de buscar todos los correos electrónicos de un remitente concreto y resumir su contenido.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "831d29b1"
      },
      "source": [
        "# Resolución del caso práctico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V8dgd_BUeOK"
      },
      "source": [
        "## 0. Instalación de librerías externas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScQcgtCkUhD7"
      },
      "outputs": [],
      "source": [
        "#!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7d620f6"
      },
      "source": [
        "## 1. Lectura de la API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_pc_repo = \"C:/Users/Osvaldo/OneDrive/Documents/3. Projectos Visual Studio/GenerativeAI/\"\n",
        "path_repo = \"data/data\"\n",
        "key_path = \"/5. Aplicaciones LLMs-ChatBot/\"\n",
        "file_info = \"/api-key.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "path_file = path_pc_repo + key_path + file_info\n",
        "\n",
        "#with open(\"/content/drive/MyDrive/api-keys/secret-key.txt\") as f:\n",
        "#  openai.api_key = f.readline()\n",
        "\n",
        "with open(path_file ) as f:\n",
        "  openai.api_key = f.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjNFCLMHWCXs"
      },
      "source": [
        "## 2. Selección del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP3Zs5O1WHER"
      },
      "source": [
        "En la función `obtener_completion` que habíamos implementado para casos prácticos anteriores, únicamente hacíamos uso del `role` de `user`:\n",
        "\n",
        "```python\n",
        "def obtener_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "  mensaje = [{\"role\": \"user\", \"content\": prompt}]\n",
        "  respuesta = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=mensaje,\n",
        "      temperature=0, # Este hiperparámetro controla la aleatoriedad del modelo\n",
        "  )\n",
        "  return respuesta.choices[0].message[\"content\"]\n",
        "```\n",
        "\n",
        "En este caso práctico, vamos a tener que explorar el [resto de roles que nos proporcionar OpenAI](https://platform.openai.com/docs/guides/gpt/chat-completions-api) para sus LLMs y la función que tienen cada uno de ellos:\n",
        "\n",
        "\n",
        "*  Rol `user`: Representa al usuario final que interactúa con el LLM a través de un chat.\n",
        "*  Rol `assistant`: Representa al LLM que estemos utilizando, en este caso, `gpt-3.5-turbo`.\n",
        "*  Rol `system`: Este rol representa al desarrollador de sistema. Permite proporcionar instrucciones \"root\" al LLM para que se sigan durante la conversación con el usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkxOGRD-WF3p"
      },
      "outputs": [],
      "source": [
        "def obtener_completion(mensajes, model=\"gpt-3.5-turbo\"):\n",
        "  respuesta = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=mensajes,\n",
        "      temperature=0, # Este hiperparámetro controla la aleatoriedad del modelo\n",
        "  )\n",
        "  return respuesta.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkaO77uQOPZ8"
      },
      "source": [
        "## 3. Integración con Gmail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9a_oOX9j7FA"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnMQVlBpIYJM"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os.path\n",
        "import base64\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "\n",
        "# If modifying these scopes, delete the file token.json.\n",
        "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
        "\n",
        "\n",
        "def obtener_correos(remitente):\n",
        "    \"\"\"Proporciona los correos electrónicos del usuario.\"\"\"\n",
        "    creds = None\n",
        "    if os.path.exists('/content/drive/MyDrive/api-keys/token.json'):\n",
        "        creds = Credentials.from_authorized_user_file('/content/drive/MyDrive/api-keys/token.json', SCOPES)\n",
        "\n",
        "    try:\n",
        "        correos = \"\"\"\"\"\"\n",
        "        service = build('gmail', 'v1', credentials=creds)\n",
        "        results = service.users().messages().list(userId='me', labelIds=['INBOX']).execute()\n",
        "        # Recorremos todos los correos electrónicos\n",
        "        for msg in results['messages']:\n",
        "          mensaje = service.users().messages().get(userId='me', id=msg['id']).execute()\n",
        "          # Comparamos el remitente del correo\n",
        "          if remitente in str(mensaje['payload']['headers'][14]):\n",
        "            # Extraemos el contenido del correo\n",
        "            datos = base64.b64decode(mensaje['payload']['parts'][0]['body']['data'], '-_')\n",
        "            correos += f\"\"\"\n",
        "'''\n",
        "Contenido: {datos}\n",
        "'''\n",
        "\"\"\"\n",
        "        return correos\n",
        "\n",
        "    except HttpError as error:\n",
        "        # TODO(developer) - Handle errors from gmail API.\n",
        "        print(f'An error occurred: {error}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYLKpcDOOY2o"
      },
      "outputs": [],
      "source": [
        "print(obtener_correos(\"shramos@protonmail.com\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WplHNlNhiQP"
      },
      "source": [
        "## 4. Implementación de un ChatBot interactivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gClV6n5kfZV"
      },
      "outputs": [],
      "source": [
        "def collect_messages(_):\n",
        "    prompt = inp.value_input\n",
        "    inp.value = ''\n",
        "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
        "    response = obtener_completion(context)\n",
        "    try:\n",
        "      remitente = eval(response)[\"remitente\"]\n",
        "      accion_solicitada = eval(response)[\"accion_solicitada\"]\n",
        "      correos = obtener_correos(remitente)\n",
        "      context.pop(0) # Elimino del contexto la regla inicial\n",
        "      context.append({'role': 'user', 'content': f\"Realiza la siguiente acción: {accion_solicitada} sobre los siguientes correos electrónicos: {correos}\"})\n",
        "      response = obtener_completion(context)\n",
        "    except:\n",
        "      pass\n",
        "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
        "    panels.append(\n",
        "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, styles={'background-color': '#F6F6F6'})))\n",
        "    return pn.Column(*panels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DWyA21Cp5pL"
      },
      "outputs": [],
      "source": [
        "def end_chat(event):\n",
        "    panels.append(pn.pane.Alert(\"Chat terminado por el usuario.\", alert_type='success'))\n",
        "    context.append({'role': 'system', 'content':\"Despídete del usuario de manera amable y amigable.\"})\n",
        "    response = obtener_completion(context)\n",
        "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, styles={'background-color': '#F6F6F6'})))\n",
        "    return pn.Column(*panels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0Sb46D4hgzB"
      },
      "outputs": [],
      "source": [
        "import panel as pn  # GUI\n",
        "pn.extension()\n",
        "\n",
        "panels = []\n",
        "\n",
        "context = [ {'role':'system', 'content':\n",
        "\"\"\"\n",
        "Debes solicitar al usuario que te indique una dirección de correo electrónico que no sea la suya y la tarea que quiere realizar sobre sus correos electrónicos. \\\n",
        "Con esta información, debes generar un JSON con las siguientes claves. No debes generar nada más.\n",
        "\"remitente\":<correo electrónico indicado por el usuario>\n",
        "\"accion_solicitada\":<descripción de la accion solicitada por el usuario sobre los correos electrónicos del remitente>\n",
        "\"\"\"} ]\n",
        "\n",
        "\n",
        "inp = pn.widgets.TextInput(value=\"Hola\", placeholder='Introduce texto aqui...')\n",
        "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
        "button_end_chat = pn.widgets.Button(name=\"Terminar Chat\")\n",
        "\n",
        "button_end_chat.on_click(end_chat)\n",
        "\n",
        "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    inp,\n",
        "    pn.Row(button_conversation, button_end_chat),\n",
        "    pn.panel(interactive_conversation, loading_indicator=True, sizing_mode=\"stretch_both\"),\n",
        ")\n",
        "\n",
        "dashboard"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
